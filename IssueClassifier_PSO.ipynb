{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4399a639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 05:12:50,397 - pyswarms.discrete.binary - INFO - Optimize for 100 iters with {'c1': 0, 'c2': 4.1, 'w': 0.1, 'k': 99, 'p': 2}\n",
      "pyswarms.discrete.binary:   0%|          |0/100"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete dataset loaded! Time taken: 0.14 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.discrete.binary: 100%|██████████|100/100, best_cost=0.382\n",
      "2021-12-08 14:07:01,374 - pyswarms.discrete.binary - INFO - Optimization finished | best cost: 0.3821125138427464, best pos: [1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 0 0 1\n",
      " 1 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 0 1 1 1 1 1 0 1\n",
      " 0 0 0 1 0 1 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0\n",
      " 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 0 0\n",
      " 1 1 1 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset performance on train with feature selection: 68.833 percent\n",
      "Subset performance on test with feature selection(accuracy): 66.333 percent\n",
      "Number of Features Selected :  395\n",
      "Complete  process ! Time taken: 1.0 seconds.\n",
      "F1: 66.31899747967185\n",
      "precision: 66.29406850459482\n",
      "recall: 66.4570344266739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyswarms as ps\n",
    "import time\n",
    "\n",
    "# swarm parameters\n",
    "#partical>> k>> c1+c2>> w \n",
    "'''\n",
    "C1: from 0.0 to 4.1 in steps of 0.50\n",
    "C2: 4.1- C1\n",
    "W: from 0.10 to 1 in steps of 0.2.\n",
    "Neighborhood Size: from 2 to all in steps of 2.\n",
    "'''\n",
    "\n",
    "options = {'c1': 0, 'c2': 4.1, 'w':0.1,'k':99,'p':2}\n",
    "num_particles_for_pso = 100   #to be change     #10-200 >>20+\n",
    "num_iters_for_pso = 100\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "df = pd.read_csv('/Users/afrah/Desktop/cs789_cs769_project/data4test/vectors_dataset.csv') ## Loading the dataset\n",
    "x = df.drop('label',axis =1)\n",
    "y = df['label']\n",
    "print(\"Complete dataset loaded! Time taken:\", round(time.time() - start,2), \"seconds.\")\n",
    "\n",
    "#devide dataset into train & test\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20,random_state =42)\n",
    "X = X_train.values\n",
    "y = y_train.values\n",
    "\n",
    "\n",
    "num_dims = X.shape[1]\n",
    "particleScore = list()\n",
    "particleSize = list()\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create an instance of the classifier\n",
    "\n",
    "from sklearn.svm import SVC # for Support Vector Classification model\n",
    "classifier = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "# Define objective function\n",
    "def f_per_particle(m, alpha):\n",
    "    \"\"\"Computes for the objective function per particle\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    m : numpy.ndarray\n",
    "        Binary mask that can be obtained from BinaryPSO, will\n",
    "        be used to mask features.\n",
    "    alpha: float (default is 0.5)\n",
    "        Constant weight for trading-off classifier performance\n",
    "        and number of features\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Computed objective function\n",
    "    \"\"\"\n",
    "    total_features = num_dims\n",
    "\n",
    "    # Get the subset of the features from the binary mask\n",
    "    if np.count_nonzero(m) == 0:\n",
    "        X_subset = X\n",
    "    else:\n",
    "        X_subset = X[:, m == 1]\n",
    "    scores = cross_val_score(classifier, X_subset, y, cv=3)\n",
    "    #print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    P = scores.mean()\n",
    "    particleScore.append(P)\n",
    "    particleSize.append(X_subset.shape[1])\n",
    "    # Compute for the objective function\n",
    "    j = (alpha * (1.0 - P)\n",
    "        + (1.0 - alpha) * (1 - (X_subset.shape[1] / total_features)))\n",
    "    \n",
    "    #j = (alpha * (1.0 - P)) + (1 - alpha) * (1 - (total_features - X_subset.shape[1]) / total_features)\n",
    "    #print(\"Particle j: \", j)\n",
    "    return j\n",
    "\n",
    "\n",
    "\n",
    "def f(x, alpha=0.88):\n",
    "    \"\"\"Higher-level method to do classification in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = x.shape[0]\n",
    "    j = [f_per_particle(x[i], alpha) for i in range(n_particles)]\n",
    "    return np.array(j)\n",
    "\n",
    "\n",
    "# Call instance of PSO\n",
    "dimensions = num_dims # dimensions should be the number of features\n",
    "# optimizer.reset()\n",
    "optimizer = ps.discrete.BinaryPSO(n_particles=num_particles_for_pso, dimensions=dimensions, options=options)\n",
    "\n",
    "# Perform optimization\n",
    "cost, pos = optimizer.optimize(f, iters=num_iters_for_pso, verbose=2)\n",
    "\n",
    "\n",
    "\n",
    "# classifier =  svm.SVC(kernel = 'linear') # Linear Kernel\n",
    "# Get the selected features from the final positions\n",
    "X_selected_features = X[:,pos==1]  # subset\n",
    "X_selected_test = X_test.values[:,pos==1]\n",
    "start = time.time()\n",
    "\n",
    "classifier = SVC(kernel='rbf', probability=True)\n",
    "classifier.fit(X_selected_features, y)\n",
    "subset_performance_train = (classifier.predict(X_selected_features) == y).mean()\n",
    "print('Subset performance on train with feature selection: %.3f percent' % (100*subset_performance_train))\n",
    "subset_performance_test = (classifier.predict(X_selected_test) == y_test.values).mean()\n",
    "print('Subset performance on test with feature selection(accuracy): %.3f percent' % (100*subset_performance_test))\n",
    "\n",
    "#find selected features\n",
    "selectd_pos = np.array(pos)\n",
    "Num_features=np.count_nonzero(y == 1)\n",
    "print(\"Number of Features Selected : \", Num_features)\n",
    "print(\"Complete  process ! Time taken:\", round(time.time() - start,2), \"seconds.\")\n",
    "\n",
    "#calculate metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "y_pred = classifier.predict(X_selected_test)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "precision = precision_score(y_test, y_pred, average=\"macro\")\n",
    "recall = recall_score(y_test, y_pred, average=\"macro\")\n",
    "print('F1:', (100*f1))\n",
    "print('precision:',(100*precision))\n",
    "print('recall:',(100*recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d78b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b786efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.66      0.68       100\n",
      "         1.0       0.68      0.68      0.68       105\n",
      "         2.0       0.61      0.65      0.63        95\n",
      "\n",
      "    accuracy                           0.66       300\n",
      "   macro avg       0.66      0.66      0.66       300\n",
      "weighted avg       0.67      0.66      0.66       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(classification_report(classifier.predict(X_selected_test),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "769e97b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bade3bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectd_pos = np.array(pos)\n",
    "Num_features=selectd_pos[(selectd_pos > 0)]\n",
    "len(Num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5928027a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
